{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6j-L1snIJB0m",
        "outputId": "3bda5bd7-7cc5-4b12-a23e-d331b5118e27"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing file: CAE1_12_24_10_256_6_100_256.xlsx\n",
            "[[-0.4490005  -0.26289159 -0.37953266 ...  0.37821412 -0.58518424\n",
            "  -0.29320558]\n",
            " [-0.52169056 -0.03284657 -0.24281687 ...  0.21467911  1.31858802\n",
            "  -0.10334295]\n",
            " [-0.45785978 -0.33491602 -0.39202644 ...  1.56691554 -1.09125992\n",
            "   0.90747382]\n",
            " ...\n",
            " [-0.44020941 -0.17266458 -0.3711579  ... -0.65444145  0.45361158\n",
            "   0.81141229]\n",
            " [-0.42287775 -0.27477486 -0.34188762 ...  0.06280107  2.09563878\n",
            "   1.39112906]\n",
            " [ 1.04425631 -0.32367347  0.1217961  ... -0.1034195  -0.30326432\n",
            "  -0.36036706]]\n",
            "Extracted CAE Hyperparameters:\n",
            "{'s1': 12, 's2': 24, 's3': 10, 's4': 256, 's5': 6, 's6': 100, 's7': 256}\n",
            "698/698 [==============================] - 1s 2ms/step\n",
            "Classifier: LinearDiscriminantAnalysis\n",
            "Accuracy: 0.758858234295416\n",
            "Selected Features: ('1', '2', '3', '4', '5', '6', '8', '9', '11', '12', '15', '16', '17', '20', '22')\n",
            "Feature Score: 0.7481953926798235\n",
            "Classifier: ExtraTreesClassifier\n",
            "Accuracy: 0.8295483991378584\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv1D, Flatten, Dense, Reshape, Conv1DTranspose\n",
        "from keras.optimizers import Adam\n",
        "import os\n",
        "import re\n",
        "from warnings import simplefilter\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "\n",
        "# Suppress ConvergenceWarning\n",
        "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "# Define the file names\n",
        "file_names = [\n",
        "    \"CAE1_12_24_10_256_6_100_256.xlsx\",\n",
        "    \"CAE1_16_32_14_256_6_100_128.xlsx\",\n",
        "    \"CAE2_16_32_14_256_6_100_256.xlsx\",\n",
        "    \"CAE2_32_64_16_256_6_75_256.xlsx\",\n",
        "]\n",
        "\n",
        "def load_data(file_name):\n",
        "    # Load data\n",
        "    df = pd.read_excel(file_name, header=[0, 1])  # Load with multi-level header\n",
        "    feature_names = df.columns.to_flat_index()  # Get multi-level index\n",
        "    X = df.values[:, :-1]  # Features (remove the last column which is the class label)\n",
        "    y = df.values[:, -1]   # Class labels (last column)\n",
        "    return X, y, feature_names\n",
        "\n",
        "def preprocess_data(X):\n",
        "    # Scale the data\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    return X_scaled\n",
        "\n",
        "def extract_cae_hyperparameters(file_name):\n",
        "    # Extract CAE hyperparameters from the file name\n",
        "    pattern = r\"(CAE\\d)_(\\d+)_(\\d+)_(\\d+)_(\\d+)_(\\d+)_(\\d+)_(\\d+)\\.xlsx\"\n",
        "    match = re.match(pattern, file_name)\n",
        "\n",
        "    if match:\n",
        "        cae_type = match.group(1)\n",
        "        s1 = int(match.group(2))\n",
        "        s2 = int(match.group(3))\n",
        "        s3 = int(match.group(4))\n",
        "        s4 = int(match.group(5))\n",
        "        s5 = int(match.group(6))\n",
        "        s6 = int(match.group(7))\n",
        "        s7 = int(match.group(8))\n",
        "\n",
        "        return {\n",
        "            \"s1\": s1,\n",
        "            \"s2\": s2,\n",
        "            \"s3\": s3,\n",
        "            \"s4\": s4,\n",
        "            \"s5\": s5,\n",
        "            \"s6\": s6,\n",
        "            \"s7\": s7\n",
        "        }\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def build_cae(input_shape, num_original_features, s1, s2, s3, s4, s5, s6, s7):\n",
        "    # Build Convolutional Autoencoder (CAE) based on extracted hyperparameters\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    x = Conv1D(s1, 3, activation='relu', padding='same')(inputs)\n",
        "    x = Conv1D(s2, 3, activation='relu', padding='same')(x)\n",
        "    x = Flatten()(x)\n",
        "    encoded = Dense(s5, activation='relu')(x)\n",
        "\n",
        "    # Decoder\n",
        "    x = Dense(s4, activation='relu')(encoded)\n",
        "    x = Dense(num_original_features, activation='relu')(x)\n",
        "    x = Reshape((num_original_features, 1))(x)\n",
        "    x = Conv1DTranspose(s3, 3, activation='relu', padding='same')(x)\n",
        "    x = Conv1DTranspose(s2, 3, activation='relu', padding='same')(x)\n",
        "    decoded = Conv1DTranspose(1, 3, activation='linear', padding='same')(x)\n",
        "\n",
        "    autoencoder = Model(inputs, decoded)\n",
        "    autoencoder.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "\n",
        "    encoder = Model(inputs, encoded)\n",
        "    return autoencoder, encoder\n",
        "\n",
        "def feature_extraction(X, encoder):\n",
        "    # Extract deep features using CAE encoder\n",
        "    deep_features = encoder.predict(X)\n",
        "    return deep_features\n",
        "\n",
        "def evaluate_classification(X, y, clf):\n",
        "    # Evaluate classification performance\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    scores = cross_val_score(clf, X, y, cv=kf)\n",
        "    return scores.mean()\n",
        "\n",
        "def apply_ffs(X, y, clf):\n",
        "    # Apply Forward Feature Selection\n",
        "    sfs = SFS(clf,\n",
        "              k_features='best',\n",
        "              forward=True,\n",
        "              floating=False,\n",
        "              verbose=0,\n",
        "              scoring='accuracy',\n",
        "              cv=5) #lower cv for testing\n",
        "    sfs.fit(X, y)\n",
        "    return sfs.k_feature_names_, sfs.k_score_\n",
        "\n",
        "for file_name in file_names:\n",
        "    print(\"Processing file:\", file_name)\n",
        "\n",
        "    # Load data\n",
        "    X, y, feature_names = load_data(file_name)\n",
        "\n",
        "    # Preprocess data\n",
        "    X_scaled = preprocess_data(X)\n",
        "\n",
        "    print(X_scaled)\n",
        "\n",
        "    # Extract CAE hyperparameters\n",
        "    cae_hyperparameters = extract_cae_hyperparameters(file_name)\n",
        "    print(\"Extracted CAE Hyperparameters:\")\n",
        "    print(cae_hyperparameters)\n",
        "\n",
        "    # Build and train CAE\n",
        "    input_shape = (X_scaled.shape[1], 1)\n",
        "    num_original_features = X_scaled.shape[1]\n",
        "    cae, encoder = build_cae(input_shape, num_original_features, **cae_hyperparameters)\n",
        "    cae.fit(X_scaled, X_scaled, epochs=50, batch_size=32, verbose=0) #lower epochs for testing\n",
        "\n",
        "    # Extract deep features\n",
        "    deep_features = feature_extraction(X_scaled, encoder)\n",
        "\n",
        "    # Trim deep features to match number of original features\n",
        "    deep_features = deep_features[:, :num_original_features]\n",
        "\n",
        "    # Combine Standard and Deep Features\n",
        "    X_combined = np.hstack((X_scaled, deep_features))\n",
        "\n",
        "    # Initialize and evaluate classifiers\n",
        "    classifiers = [\n",
        "        LDA(solver='lsqr'),\n",
        "        #MLPClassifier(hidden_layer_sizes=(10, 5)), tune this and maybe adjust cv= in apply_ffs\n",
        "        ExtraTreesClassifier(n_estimators=100)\n",
        "    ]\n",
        "\n",
        "    for clf in classifiers:\n",
        "        try:\n",
        "            print(\"Classifier:\", clf.__class__.__name__)\n",
        "\n",
        "            # Evaluate classification performance\n",
        "            accuracy = evaluate_classification(X_combined, y, clf)\n",
        "            print(\"Accuracy:\", accuracy)\n",
        "\n",
        "            # Apply Forward Feature Selection\n",
        "            selected_features, feature_score = apply_ffs(X_combined, y, clf)\n",
        "            print(\"Selected Features:\", selected_features)\n",
        "            print(\"Feature Score:\", feature_score)\n",
        "        except Exception as e:\n",
        "            print(\"Error processing classifier\", clf.__class__.__name__)\n",
        "            print(e)\n",
        "\n",
        "    print(\"-\" * 80)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}